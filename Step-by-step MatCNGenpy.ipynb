{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MatCNGenPy\n",
    "\n",
    "This is a python implementation of the algorithms described in \n",
    "**Efficient Match-Based Candidate Network Generation for Keyword \n",
    "Queries over Relational Databases** paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "from pprint import pprint as pp\n",
    "from collections import defaultdict\n",
    "import string\n",
    "import itertools\n",
    "import copy\n",
    "from math import log1p\n",
    "from queue import deque\n",
    "import ast\n",
    "import gc\n",
    "from queue import deque\n",
    "\n",
    "import nltk \n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('omw')\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "stw_set = set(stopwords.words('english')) - {'will'}\n",
    "\n",
    "# Connect to an existing database\n",
    "conn = psycopg2.connect(\"dbname=imdb user=postgres\")\n",
    "\n",
    "# Open a cursor to perform database operations\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Antes mesmo de receber os querysets, o sistema passa por um pré-processamento, que é responsavél pela criação de dois índices invertidos:\n",
    "\n",
    "* **wordHash**: tabela que associa cada termo do banco de dados com o seu **IAF (Inverse Attribute Frequency)** e também referencia todas Tabelas, Colunas e CTIDs em que a palavra ocorre. Nota: o CTID é o endereço físico de uma linha em uma tabela, utilizado para encontrar rapidamente uma tupla.\n",
    "```python\n",
    "wordHash['term'] = ( IAF , { 'table': { 'column' : [ctid] } } )\n",
    "```\n",
    "* **attributeHash**: tabela que para cada atributo (documento), armazena a sua norma e o número de palavras distintas.\n",
    "```python\n",
    "attributeHash['table']['column'] = ( norm , num_distinct_words )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação dos Índices Invertidos\n",
    "\n",
    "O processo de criação é realizado em três etapas. Primeiramente, o procedimento ```createInvertedIndex()``` faz uma varredura no banco de dados e preenche parcialmente o ```wordHash```, faltando apenas calcular os IAFs para cada termo. Além disso, este procedimento também ele também armazena no ```attributeHash``` o total de palavras distintas para cada atributo.\n",
    "\n",
    "Em seguida, os IAFs de cada termo são processados através do método ```processIAF(wordHash,attributeHash)```. Por último, as normas dos atributos (documentos) são calculadas no método ```processNormsOfAttributes(wordHash,attributeHash)```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INDEXING TABLE  casting\n",
      "INDEXING TABLE  role\n",
      "INDEXING TABLE  movie\n",
      "INDEXING TABLE  char\n",
      "INDEXING TABLE  person\n",
      "INVERTED INDEX CREATED\n"
     ]
    }
   ],
   "source": [
    "def createInvertedIndex():\n",
    "    #Output: wordHash (Term Index) with this structure below\n",
    "    #map['word'] = [ 'table': ( {column} , ['ctid'] ) ]\n",
    "\n",
    "    '''\n",
    "    The Term Index is built in a preprocessing step that scans only\n",
    "    once all the relations over which the queries will be issued.\n",
    "    '''\n",
    "    \n",
    "    wordHash = {}\n",
    "    attributeHash = {}\n",
    "    \n",
    "    # Get list of tablenames\n",
    "    cur.execute(\"SELECT DISTINCT tablename FROM pg_tables WHERE schemaname!='pg_catalog' AND schemaname !='information_schema';\")\n",
    "    for table in cur.fetchall():\n",
    "        table_name = table[0]\n",
    "        print('INDEXING TABLE ',table_name)\n",
    "        \n",
    "        attributeHash[table_name] = {}\n",
    "        \n",
    "        #Get all tuples for this tablename\n",
    "        cur.execute(\n",
    "            sql.SQL(\"SELECT ctid, * FROM {};\").format(sql.Identifier(table_name))\n",
    "            #NOTE: sql.SQL is needed to specify this parameter as table name (can't be passed as execute second parameter)\n",
    "        )\n",
    "\n",
    "        for row in cur.fetchall():\n",
    "            for column in range(1,len(row)):\n",
    "                column_name = cur.description[column][0]   \n",
    "                ctid = row[0]\n",
    "\n",
    "                for word in [word.strip(string.punctuation) for word in str(row[column]).lower().split()]:\n",
    "                    \n",
    "                    #Ignoring STOPWORDS\n",
    "                    if word in stw_set:\n",
    "                        continue\n",
    "\n",
    "                    #If word entry doesn't exists, it will be inicialized (setdefault method),\n",
    "                    #Append the location for this word\n",
    "                    wordHash.setdefault(word, {})                    \n",
    "                    wordHash[word].setdefault( table_name , {} )\n",
    "                    wordHash[word][table_name].setdefault( column_name , [] ).append(ctid)\n",
    "                    \n",
    "                    attributeHash[table_name].setdefault(column_name,(0,set()))\n",
    "                    attributeHash[table_name][column_name][1].add(word)\n",
    "        \n",
    "        #Count words\n",
    "        \n",
    "        for (column_name,(norm,wordSet)) in attributeHash[table_name].items():\n",
    "            num_distinct_words = len(wordSet)\n",
    "            wordSet.clear()\n",
    "            attributeHash[table_name][column_name] = (norm,num_distinct_words)\n",
    "        \n",
    "\n",
    "    print ('INVERTED INDEX CREATED')\n",
    "    return (wordHash,attributeHash)\n",
    "\n",
    "(wordHash,attributeHash) = createInvertedIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'casting': {'note': ['(2394,52)', '(3822,72)']},\n",
      " 'char': {'name': ['(858,89)']},\n",
      " 'person': {'name': ['(206,57)',\n",
      "                     '(589,99)',\n",
      "                     '(615,91)',\n",
      "                     '(722,53)',\n",
      "                     '(987,44)',\n",
      "                     '(1211,109)',\n",
      "                     '(1257,105)',\n",
      "                     '(1409,17)',\n",
      "                     '(1670,26)',\n",
      "                     '(1840,55)',\n",
      "                     '(1959,105)',\n",
      "                     '(2177,95)']}}\n"
     ]
    }
   ],
   "source": [
    "pp(wordHash['denzel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__search_id': (0, 181706),\n",
      " 'episode_nr': (0, 1),\n",
      " 'episode_of_id': (0, 1),\n",
      " 'id': (0, 181706),\n",
      " 'imdb_id': (0, 1),\n",
      " 'imdb_index': (0, 13),\n",
      " 'kind_id': (0, 1),\n",
      " 'phonetic_code': (0, 18016),\n",
      " 'production_year': (0, 123),\n",
      " 'season_nr': (0, 1),\n",
      " 'series_years': (0, 1),\n",
      " 'title': (0, 79556)}\n"
     ]
    }
   ],
   "source": [
    "pp(attributeHash['movie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IAF PROCESSED\n"
     ]
    }
   ],
   "source": [
    "def processIAF(wordHash,attributeHash):\n",
    "    \n",
    "    total_attributes = sum([len(attribute) for attribute in attributeHash.values()])\n",
    "    \n",
    "    for (term, values) in wordHash.items():\n",
    "        \n",
    "        attributes_with_this_term = sum([len(attribute) for attribute in wordHash[term].values()])\n",
    "        \n",
    "        IAF = log1p(total_attributes/attributes_with_this_term)\n",
    "                \n",
    "        wordHash[term] = (IAF,values)\n",
    "    print('IAF PROCESSED')\n",
    "\n",
    "processIAF(wordHash,attributeHash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.614959778036198,\n",
      " {'casting': {'note': ['(2394,52)', '(3822,72)']},\n",
      "  'char': {'name': ['(858,89)']},\n",
      "  'person': {'name': ['(206,57)',\n",
      "                      '(589,99)',\n",
      "                      '(615,91)',\n",
      "                      '(722,53)',\n",
      "                      '(987,44)',\n",
      "                      '(1211,109)',\n",
      "                      '(1257,105)',\n",
      "                      '(1409,17)',\n",
      "                      '(1670,26)',\n",
      "                      '(1840,55)',\n",
      "                      '(1959,105)',\n",
      "                      '(2177,95)']}})\n"
     ]
    }
   ],
   "source": [
    "pp(wordHash['denzel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSING TABLE  casting\n",
      "PROCESSING TABLE  role\n",
      "PROCESSING TABLE  movie\n",
      "PROCESSING TABLE  char\n",
      "PROCESSING TABLE  person\n",
      "NORMS OF ATTRIBUTES PROCESSED\n"
     ]
    }
   ],
   "source": [
    "def processNormsOfAttributes(wordHash,attributeHash):\n",
    "  \n",
    "    # Get list of tablenames\n",
    "    cur.execute(\"SELECT DISTINCT tablename FROM pg_tables WHERE schemaname!='pg_catalog' AND schemaname !='information_schema';\")\n",
    "    for table in cur.fetchall():\n",
    "        table_name = table[0]\n",
    "        print('PROCESSING TABLE ',table_name)\n",
    "        \n",
    "        #Get all tuples for this tablename\n",
    "        cur.execute(\n",
    "            sql.SQL(\"SELECT ctid, * FROM {};\").format(sql.Identifier(table_name))\n",
    "            #NOTE: sql.SQL is needed to specify this parameter as table name (can't be passed as execute second parameter)\n",
    "        )\n",
    "\n",
    "        for row in cur.fetchall():\n",
    "            for column in range(1,len(row)):\n",
    "                column_name = cur.description[column][0]   \n",
    "                ctid = row[0]\n",
    "\n",
    "                for word in [word.strip(string.punctuation) for word in str(row[column]).lower().split()]:\n",
    "                    \n",
    "                    #Ignoring STOPWORDS\n",
    "                    if word in stw_set:\n",
    "                        continue\n",
    "                    \n",
    "                    (prevNorm,num_distinct_words)=attributeHash[table_name][column_name]\n",
    "                    \n",
    "                    IAF = wordHash[word][0]\n",
    "                    \n",
    "                    Norm = prevNorm + IAF\n",
    "                    \n",
    "                    attributeHash[table_name][column_name]=(Norm,num_distinct_words)\n",
    "                    \n",
    "\n",
    "    print ('NORMS OF ATTRIBUTES PROCESSED')\n",
    "\n",
    "processNormsOfAttributes(wordHash,attributeHash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__search_id': (665691.1324713555, 181706),\n",
      " 'episode_nr': (187705.0247137609, 1),\n",
      " 'episode_of_id': (187705.0247137609, 1),\n",
      " 'id': (510658.84283990104, 181706),\n",
      " 'imdb_id': (187705.0247137609, 1),\n",
      " 'imdb_index': (186715.63296297463, 13),\n",
      " 'kind_id': (271455.1406490868, 1),\n",
      " 'phonetic_code': (406945.19711942895, 18016),\n",
      " 'production_year': (413884.3735530032, 123),\n",
      " 'season_nr': (187705.0247137609, 1),\n",
      " 'series_years': (187705.0247137609, 1),\n",
      " 'title': (1192600.3265680545, 79556)}\n"
     ]
    }
   ],
   "source": [
    "pp(attributeHash['movie'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main\n",
    "\n",
    "O processamento das consultas é realizado em "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['will', 'smith'],\n",
       " ['sound', 'music'],\n",
       " ['forrest', 'gump'],\n",
       " ['casablanca'],\n",
       " ['best', 'movie', 'award', 'James', 'Cameron'],\n",
       " ['actor', 'James', 'Bond'],\n",
       " ['movie', 'Ellen', 'Page', 'thriller'],\n",
       " ['movie', 'Terry', 'Gilliam', 'Benicio', 'del', 'Toro', 'Dr', 'gonzo'],\n",
       " ['director', 'artificial', 'intelligent', 'Haley', 'Joel', 'Osment'],\n",
       " ['Trivia', 'Don', 'Quixote'],\n",
       " ['Movie', 'Steven', 'Spielberg'],\n",
       " ['German', 'fellow', 'actor', 'Mel', 'Gibson'],\n",
       " ['actor',\n",
       "  'The',\n",
       "  'Fellowship',\n",
       "  'Ring',\n",
       "  'The',\n",
       "  'Return',\n",
       "  'King',\n",
       "  'The',\n",
       "  'Two',\n",
       "  'Towers'],\n",
       " ['Director', 'John', 'Hughes', 'Matthew', 'Broderick', '1986'],\n",
       " ['cast', 'Friends'],\n",
       " ['forrest', 'gump'],\n",
       " ['henry', 'fonda', 'mine'],\n",
       " ['russell', 'crowe', 'gladiator'],\n",
       " ['darth', 'vader'],\n",
       " ['norman', 'bates'],\n",
       " ['atticus', 'finch']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getQuerySets():\n",
    "    QuerySet = []\n",
    "    with open('querysets/queryset_imdb_martins.txt') as f:\n",
    "        for line in f.readlines():\n",
    "            \n",
    "            #The line bellow Remove words not in OLIVEIRA experiments\n",
    "            Q = [word.strip(string.punctuation) for word in line.split() if word not in ['title','dr.',\"here's\",'char','name'] and word not in stw_set]  \n",
    "            \n",
    "            #Q = [word.strip(string.punctuation) for word in line.split() if word not in stw_set]  \n",
    "            \n",
    "            QuerySet.append(Q)\n",
    "    return QuerySet\n",
    "        \n",
    "QuerySet = getQuerySets()\n",
    "QuerySet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Tuple-sets\n",
    "Esta etapa consiste em recuperar conjuntos de tuplas que contém cada palavra-chave, chamados de tuple-sets. O algoritmo `TSFind`, que realiza esse processo, pode ser é divido em três partes: \n",
    "* **Recuperação de tuplas:** Essa parte consiste em encontrar os conjuntos de tuplas que contém cada uma das palavras do Queryset. Essas informações já foram pré-processadas no índice invertido `wordHash`.\n",
    "* **Interseção de tuplas:** Esta parte acontece no algoritmo `TSInter` e é responsável por encontrar tuplas que contém mais de uma das palavras-chave. Além disso, esta etapa irá garantir que os tuple-sets `TABLE{word}` contenham apenas a palavra `word` e nenhuma outra palavra do queryset. Esta propriedade é necessária para encontrar a cobertura mínima (etapa de criação de query matches). \n",
    "* **Criação de tuple-sets:** Esta parte irá condensar os resultados. Em vez de listar todas as tuplas que contenham as palavras-chave, precisamos apenas saber quais colunas possuem cada uma das palavras. Por isso, os tuple-sets terão a estrutura (o primeiro atributo refere-se a *value* ou *schema*):\n",
    "```python\n",
    "TupleSet = ('v','table','column', frozenset({words}))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TUPLE SETS CREATED\n",
      "{('v', 'casting', 'note', frozenset({'bond'})),\n",
      " ('v', 'casting', 'note', frozenset({'actor'})),\n",
      " ('v', 'casting', 'note', frozenset({'james'})),\n",
      " ('v', 'casting', 'note', frozenset({'james', 'actor'})),\n",
      " ('v', 'casting', 'note', frozenset({'bond', 'james'})),\n",
      " ('v', 'char', 'name', frozenset({'james'})),\n",
      " ('v', 'char', 'name', frozenset({'bond', 'james'})),\n",
      " ('v', 'char', 'name', frozenset({'james', 'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'bond'})),\n",
      " ('v', 'char', 'name', frozenset({'actor'})),\n",
      " ('v', 'movie', 'title', frozenset({'bond'})),\n",
      " ('v', 'movie', 'title', frozenset({'actor'})),\n",
      " ('v', 'movie', 'title', frozenset({'james'})),\n",
      " ('v', 'movie', 'title', frozenset({'bond', 'james'})),\n",
      " ('v', 'person', 'name', frozenset({'bond'})),\n",
      " ('v', 'person', 'name', frozenset({'james'})),\n",
      " ('v', 'person', 'name', frozenset({'bond', 'james'})),\n",
      " ('v', 'person', 'name', frozenset({'james', 'actor'})),\n",
      " ('v', 'role', 'role', frozenset({'actor'}))}\n"
     ]
    }
   ],
   "source": [
    "def TSFind(Q):\n",
    "    #Input:  A keyword query Q=[k1, k2, . . . , km]\n",
    "    #Output: Set of non-free and non-empty tuple-sets Rq\n",
    "\n",
    "    '''\n",
    "    The tuple-set Rki contains the tuples of Ri that contain all\n",
    "    terms of K and no other keywords from Q\n",
    "    '''\n",
    "    \n",
    "    #Part 1: Find sets of tuples containing each keyword\n",
    "    global P\n",
    "    P = {}\n",
    "    for keyword in Q:\n",
    "        tupleset = set()\n",
    "        \n",
    "        if keyword not in wordHash:\n",
    "            continue\n",
    "        \n",
    "        for (table,attributes) in wordHash.get(keyword)[1].items():\n",
    "            for (attribute,ctids) in attributes.items():\n",
    "                for ctid in ctids:\n",
    "                    tupleset.add( (table,attribute,ctid) )\n",
    "        P[frozenset([keyword])] = tupleset\n",
    "    \n",
    "    #Part 2: Find sets of tuples containing larger termsets\n",
    "    P = TSInter(P)\n",
    "    \n",
    "    #Part 3:Build tuple-sets\n",
    "    Rq = set()\n",
    "    for keyword , tuples in P.items():\n",
    "        for (table,attribute,ctid) in tuples:\n",
    "            Rq.add( ('v',table,attribute,keyword) )\n",
    "    print ('TUPLE SETS CREATED')\n",
    "    return Rq\n",
    "\n",
    "\n",
    "def TSInter(P):\n",
    "    #Input: A Set of non-empty tuple-sets for each keyword alone P \n",
    "    #Output: The Set P, but now including larger termsets (process Intersections)\n",
    "\n",
    "    '''\n",
    "    Termset is any non-empty subset K of the terms of a query Q        \n",
    "    '''\n",
    "    \n",
    "    Pprev = {}\n",
    "    Pprev=copy.deepcopy(P)\n",
    "    Pcurr = {}\n",
    "\n",
    "    combinations = [x for x in itertools.combinations(Pprev.keys(),2)]\n",
    "    for ( Ki , Kj ) in combinations:\n",
    "        Tki = Pprev[Ki]\n",
    "        Tkj = Pprev[Kj]\n",
    "        \n",
    "        X = Ki | Kj\n",
    "        Tx = Tki & Tkj        \n",
    "        \n",
    "        if len(Tx) > 0:            \n",
    "            Pcurr[X]  = Tx            \n",
    "            Pprev[Ki] = Tki - Tx         \n",
    "            Pprev[Kj] = Tkj - Tx\n",
    "            \n",
    "    if Pcurr != {}:\n",
    "        Pcurr = copy.deepcopy(TSInter(Pcurr))\n",
    "        \n",
    "    #Pprev = Pprev U Pcurr\n",
    "    Pprev.update(Pcurr)     \n",
    "    return Pprev   \n",
    "\n",
    "Q = ['actor', 'james', 'bond']\n",
    "Rq = TSFind(Q)\n",
    "pp(Rq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Schema-sets\n",
    "\n",
    "Esta etapa consiste na criação dos Schema-sets, que é uma estrutura análoga aos tuple-sets vistos na etapa anterior. Aqui, o processo também é divido em três partes: \n",
    "* **Mapeamento de Elementos do Esquema (*Schema Matching*):** Essa parte consiste em analisar a similaridade entre as palavras do querysets e elementos do esquema (nomes de relações e atributos).\n",
    "* **Análise de Termos Adjacentes:** Esta parte verifica as relações entre as palavras chave, muitas vezes uma palavras-chave relacioada a elemento do esquema delimita o domínio das palavras-chave adjacentes. Ex: Actor James Bond delimita a palavra James para nome de Pessoa, em vez de nome de Filme.\n",
    "* **Criação de Schema-sets:** Esta parte irá formatar os resultados para ficarem semelhantes à estrutura de tuple-sets, seguindo a estrutura a seguir (o primeiro atributo refere-se a *value* ou *schema*):\n",
    "```python\n",
    "SchemaSet = ('s','table','column', frozenset({words}))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similaridades para o Schema-Matching\n",
    "\n",
    "Para o mapeamento de palavras para elementos do esquema, foram utilizadas métricas de similaridade de escrita e semântica.\n",
    "O Coeficiente de Jaccard é uma métrica que avalia a interseção entre duas palavras, sendo ideal para similaridades de escrita, como abreviações ou erros de digitação. \n",
    "\n",
    "Por outro lado, as métricas semânticas utilizam o dicionário léxico WordNet para encontrar similaridades de sentido. O pacote de ferramentas NLTK disponibiliza uma série de métricas semânticas [aqui](http://www.nltk.org/howto/wordnet.html \"WordNet Interface\"). Entre elas, as principais são a Path Similarity e a Wu-Palmer Similarity. A primeira métrica procura encontrar a menor distância entre duas palavras, no grafo de relações do WordNet, enquanto a segunda analisa o ancestral comum mais próximo entre duas palavras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordNetSimilarity(wordA,wordB):\n",
    "    \n",
    "    A = set(wn.synsets(wordA))\n",
    "    B = set(wn.synsets(wordB))\n",
    "    \n",
    "    wupSimilarities = [0]\n",
    "    pathSimilarities = [0]\n",
    "    for (sense1,sense2) in itertools.product(A,B):        \n",
    "        wupSimilarities.append(wn.wup_similarity(sense1,sense2) or 0)\n",
    "        pathSimilarities.append(wn.path_similarity(sense1,sense2) or 0)\n",
    "    return max(max(wupSimilarities),max(pathSimilarities))\n",
    "\n",
    "def jaccard_similarity(wordA,wordB):\n",
    "    \n",
    "    A = set(wordA)\n",
    "    B = set(wordB)\n",
    "    \n",
    "    return len(A & B ) / len(A | B)\n",
    "    \n",
    "def wordSimilarity(wordA,wordB):\n",
    "    return max( (jaccard_similarity(wordA,wordB),wordNetSimilarity(wordA,wordB)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordSimilarity('actor','person')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo para Criação dos Schema-Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def SchSFind(Q,threshold):\n",
    "    S = []\n",
    "    \n",
    "    for (position,keyword) in enumerate(Q):\n",
    "        for (table,values) in attributeHash.items():\n",
    "            \n",
    "            sim = wordSimilarity(keyword,table)\n",
    "            if sim >= threshold:\n",
    "                S.append( (table,'*',{keyword},position,sim) )\n",
    "            \n",
    "            for attribute in values.keys():\n",
    "                \n",
    "                if(attribute=='id'):\n",
    "                    continue\n",
    "                \n",
    "                sim = wordSimilarity(keyword,attribute)\n",
    "                \n",
    "                if sim >= threshold:\n",
    "                    S.append( (table,attribute,{keyword},position,sim) )\n",
    "    #S = SchSInter(S)\n",
    "\n",
    "    print ('SCHEMA SETS CREATED')\n",
    "    Sq = {('s',table,attribute,frozenset(keywords)) for (table,attribute,keywords,position,sim) in S}\n",
    "        \n",
    "    return Sq\n",
    "\n",
    "'''\n",
    "Em vez de interseções, deve ser feita uma análise dos adjacentes..\n",
    "\n",
    "def SchSInter(S):\n",
    "    \n",
    "    Scurr= S.copy()\n",
    "    \n",
    "    somethingChanged = False\n",
    "\n",
    "    combinations = [x for x in itertools.combinations(Scurr,2)]\n",
    "    \n",
    "    for ( A , B ) in combinations:    \n",
    "    \n",
    "        (tableA,attributeA,wordsA,positionA,simA) = A\n",
    "        (tableB,attributeB,wordsB,positionB,simB) = B\n",
    "        \n",
    "        if A not in Scurr or B not in Scurr:\n",
    "            continue\n",
    "        \n",
    "        if tableA == tableB and abs(positionA-positionB)<=1:\n",
    "            print('A:\\n',A)\n",
    "            print('B:\\n',B)\n",
    "            \n",
    "            AB = (tableA, '*' , wordsA | wordsB, max((positionA,positionB)) , max((simA,simB)) )\n",
    "            \n",
    "            Scurr.remove(A)\n",
    "            Scurr.remove(B)\n",
    "            Scurr.append(AB)\n",
    "            \n",
    "            somethingChanged = True \n",
    "   \n",
    "    if somethingChanged:\n",
    "        return SchSInter(Scurr)\n",
    "    \n",
    "    return Scurr\n",
    "'''\n",
    "''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCHEMA SETS CREATED\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{('s', 'casting', 'note', frozenset({'bond'})),\n",
       " ('s', 'movie', 'title', frozenset({'bond'})),\n",
       " ('s', 'person', '*', frozenset({'actor'}))}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = QuerySet[5] = ['actor', 'james', 'bond']\n",
    "SimilarityCoeficient = 0.799999999999\n",
    "Sq = SchSFind(Q,SimilarityCoeficient)\n",
    "Sq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Matches Generation\n",
    "\n",
    "As etapas anteriores, de criação de schema-sets e tuple-sets, foram responsáveis por identificar quais relações possuem alguma informação sobre as palavras-chave. Nesta etapa de criação de full matches, o objetivo é combinar esses tuple-sets e schema-sets para se obter uma resposta completa, mínima e relevante para o usuário. \n",
    "\n",
    "O algoritmo `QMGen` é responsável por encontrar combinações de tuple-sets/schema-sets que compõem uma cobertura mínima (`MinimalCover`) sobre o queryset.\n",
    "- **Total**: Cada palavra-chave deve estar presente em ao menos uma das tuplas da query-match.\n",
    "- **Mínima**: Não é possível remover nenhum tuple-set/schema-set da query-match e manter a cobertura total sobre o queryset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MinimalCover(MC, Q):\n",
    "    #Input:  A subset MC (Match Candidate) to be checked as total and minimal cover\n",
    "    #Output: If the match candidate is a TOTAL and MINIMAL cover\n",
    "\n",
    "    Subset = [termset for category,table,attribute,termset in MC]\n",
    "    u = set().union(*Subset)    \n",
    "    \n",
    "    isTotal = (u == set(Q))\n",
    "    for element in Subset:\n",
    "        \n",
    "        new_u = list(Subset)\n",
    "        new_u.remove(element)\n",
    "        \n",
    "        new_u = set().union(*new_u)\n",
    "        \n",
    "        if new_u == set(Q):\n",
    "            return False\n",
    "    \n",
    "    return isTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QMGen(Q,Rq):\n",
    "    #Input:  A keyword query Q, The set of non-empty non-free tuple-sets Rq\n",
    "    #Output: The set Mq of query matches for Q\n",
    "    \n",
    "    '''\n",
    "    Query match is a set of tuple-sets that, if properly joined,\n",
    "    can produce networks of tuples that fulfill the query. They\n",
    "    can be thought as the leaves of a Candidate Network.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Mq = []\n",
    "    for i in range(1,len(Q)+1):\n",
    "        for subset in itertools.combinations(Rq,i):\n",
    "            if(MinimalCover(subset,Q)):\n",
    "                Mq.append(set(subset))\n",
    "    return Mq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TUPLE SETS CREATED\n",
      "SCHEMA SETS CREATED\n",
      "{('v', 'char', 'name', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'potter', 'harry'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'potter', 'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'potter', 'harry'})),\n",
      " ('v', 'person', 'name', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'potter', 'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'person', 'name', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'potter', 'harry'})),\n",
      " ('v', 'role', 'role', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'potter', 'harry'})),\n",
      " ('v', 'movie', 'title', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'potter', 'harry'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('s', 'person', '*', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'potter', 'harry'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'potter', 'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'role', 'role', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'potter', 'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'potter', 'harry'})),\n",
      " ('v', 'casting', 'note', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('s', 'person', '*', frozenset({'actor'})),\n",
      " ('v', 'casting', 'note', frozenset({'potter', 'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'person', 'name', frozenset({'harry'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'person', 'name', frozenset({'harry'})),\n",
      " ('v', 'person', 'name', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'person', 'name', frozenset({'harry'})),\n",
      " ('v', 'role', 'role', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'actor'})),\n",
      " ('v', 'person', 'name', frozenset({'harry'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'potter'})),\n",
      " ('v', 'casting', 'note', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'person', 'name', frozenset({'harry'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('s', 'person', '*', frozenset({'actor'})),\n",
      " ('v', 'casting', 'note', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'person', 'name', frozenset({'harry'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'char', 'name', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'potter'})),\n",
      " ('v', 'person', 'name', frozenset({'harry'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'potter'})),\n",
      " ('v', 'person', 'name', frozenset({'harry'})),\n",
      " ('v', 'person', 'name', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'potter'})),\n",
      " ('v', 'person', 'name', frozenset({'harry'})),\n",
      " ('v', 'role', 'role', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'potter'})),\n",
      " ('v', 'movie', 'title', frozenset({'actor'})),\n",
      " ('v', 'person', 'name', frozenset({'harry'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'potter'})),\n",
      " ('v', 'person', 'name', frozenset({'harry'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('s', 'person', '*', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'potter'})),\n",
      " ('v', 'person', 'name', frozenset({'harry'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'char', 'name', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'person', 'name', frozenset({'harry'})),\n",
      " ('v', 'person', 'name', frozenset({'potter'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'char', 'name', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'person', 'name', frozenset({'harry'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'person', 'name', frozenset({'harry'})),\n",
      " ('v', 'person', 'name', frozenset({'potter'})),\n",
      " ('v', 'person', 'name', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'person', 'name', frozenset({'harry'})),\n",
      " ('v', 'person', 'name', frozenset({'potter'})),\n",
      " ('v', 'role', 'role', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'actor'})),\n",
      " ('v', 'person', 'name', frozenset({'harry'})),\n",
      " ('v', 'person', 'name', frozenset({'potter'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'person', 'name', frozenset({'harry'})),\n",
      " ('v', 'person', 'name', frozenset({'potter'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('s', 'person', '*', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'person', 'name', frozenset({'harry'})),\n",
      " ('v', 'person', 'name', frozenset({'potter'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'char', 'name', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'person', 'name', frozenset({'harry'})),\n",
      " ('v', 'person', 'name', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'char', 'name', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'person', 'name', frozenset({'harry'})),\n",
      " ('v', 'role', 'role', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'char', 'name', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'actor'})),\n",
      " ('v', 'person', 'name', frozenset({'harry'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'person', 'name', frozenset({'harry'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('s', 'person', '*', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'person', 'name', frozenset({'harry'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'harry'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'harry'})),\n",
      " ('v', 'person', 'name', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'harry'})),\n",
      " ('v', 'role', 'role', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'harry'})),\n",
      " ('v', 'movie', 'title', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'potter'})),\n",
      " ('v', 'casting', 'note', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'harry'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('s', 'person', '*', frozenset({'actor'})),\n",
      " ('v', 'casting', 'note', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'harry'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'char', 'name', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'harry'})),\n",
      " ('v', 'movie', 'title', frozenset({'potter'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'harry'})),\n",
      " ('v', 'movie', 'title', frozenset({'potter'})),\n",
      " ('v', 'person', 'name', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'harry'})),\n",
      " ('v', 'movie', 'title', frozenset({'potter'})),\n",
      " ('v', 'role', 'role', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'harry'})),\n",
      " ('v', 'movie', 'title', frozenset({'potter'})),\n",
      " ('v', 'movie', 'title', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'harry'})),\n",
      " ('v', 'movie', 'title', frozenset({'potter'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('s', 'person', '*', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'harry'})),\n",
      " ('v', 'movie', 'title', frozenset({'potter'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'char', 'name', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'harry'})),\n",
      " ('v', 'person', 'name', frozenset({'potter'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'char', 'name', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'harry'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'harry'})),\n",
      " ('v', 'person', 'name', frozenset({'potter'})),\n",
      " ('v', 'person', 'name', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'harry'})),\n",
      " ('v', 'person', 'name', frozenset({'potter'})),\n",
      " ('v', 'role', 'role', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'harry'})),\n",
      " ('v', 'movie', 'title', frozenset({'actor'})),\n",
      " ('v', 'person', 'name', frozenset({'potter'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'harry'})),\n",
      " ('v', 'person', 'name', frozenset({'potter'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('s', 'person', '*', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'harry'})),\n",
      " ('v', 'person', 'name', frozenset({'potter'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'char', 'name', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'harry'})),\n",
      " ('v', 'person', 'name', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'char', 'name', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'harry'})),\n",
      " ('v', 'role', 'role', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'char', 'name', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'harry'})),\n",
      " ('v', 'movie', 'title', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'harry'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('s', 'person', '*', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'harry'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'harry'})),\n",
      " ('v', 'casting', 'note', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'harry'})),\n",
      " ('v', 'casting', 'note', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'person', 'name', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'harry'})),\n",
      " ('v', 'casting', 'note', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'role', 'role', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'harry'})),\n",
      " ('v', 'casting', 'note', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'harry'})),\n",
      " ('v', 'casting', 'note', frozenset({'potter'})),\n",
      " ('v', 'casting', 'note', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('s', 'person', '*', frozenset({'actor'})),\n",
      " ('v', 'casting', 'note', frozenset({'harry'})),\n",
      " ('v', 'casting', 'note', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'potter'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'potter'})),\n",
      " ('v', 'person', 'name', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'potter'})),\n",
      " ('v', 'role', 'role', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'potter'})),\n",
      " ('v', 'movie', 'title', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'harry'})),\n",
      " ('v', 'casting', 'note', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'potter'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('s', 'person', '*', frozenset({'actor'})),\n",
      " ('v', 'casting', 'note', frozenset({'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'potter'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'person', 'name', frozenset({'potter'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'person', 'name', frozenset({'potter'})),\n",
      " ('v', 'person', 'name', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'person', 'name', frozenset({'potter'})),\n",
      " ('v', 'role', 'role', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'actor'})),\n",
      " ('v', 'person', 'name', frozenset({'potter'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'harry'})),\n",
      " ('v', 'casting', 'note', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'person', 'name', frozenset({'potter'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('s', 'person', '*', frozenset({'actor'})),\n",
      " ('v', 'casting', 'note', frozenset({'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'person', 'name', frozenset({'potter'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'person', 'name', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'role', 'role', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'harry'})),\n",
      " ('v', 'casting', 'note', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('s', 'person', '*', frozenset({'actor'})),\n",
      " ('v', 'casting', 'note', frozenset({'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'person', 'name', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'role', 'role', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'potter'})),\n",
      " ('v', 'casting', 'note', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('s', 'person', '*', frozenset({'actor'})),\n",
      " ('v', 'casting', 'note', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'char', 'name', frozenset({'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'potter'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'char', 'name', frozenset({'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'potter'})),\n",
      " ('v', 'person', 'name', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'char', 'name', frozenset({'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'potter'})),\n",
      " ('v', 'role', 'role', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'char', 'name', frozenset({'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'potter'})),\n",
      " ('v', 'movie', 'title', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'potter'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('s', 'person', '*', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'potter'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'char', 'name', frozenset({'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'person', 'name', frozenset({'potter'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'char', 'name', frozenset({'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'char', 'name', frozenset({'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'person', 'name', frozenset({'potter'})),\n",
      " ('v', 'person', 'name', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'char', 'name', frozenset({'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'person', 'name', frozenset({'potter'})),\n",
      " ('v', 'role', 'role', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'char', 'name', frozenset({'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'actor'})),\n",
      " ('v', 'person', 'name', frozenset({'potter'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'person', 'name', frozenset({'potter'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('s', 'person', '*', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'person', 'name', frozenset({'potter'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'char', 'name', frozenset({'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'person', 'name', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'char', 'name', frozenset({'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'role', 'role', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'char', 'name', frozenset({'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'})),\n",
      " ('v', 'movie', 'title', frozenset({'actor'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('v', 'casting', 'note', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'}))}\n",
      "\n",
      "\n",
      "\n",
      "{('s', 'person', '*', frozenset({'actor'})),\n",
      " ('v', 'char', 'name', frozenset({'harry'})),\n",
      " ('v', 'char', 'name', frozenset({'potter'})),\n",
      " ('v', 'char', 'name', frozenset({'draco'}))}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Q =['actor', 'draco', 'harry','potter']\n",
    "\n",
    "Rq = TSFind(Q)\n",
    "SimilarityCoeficient = 0.799999999999\n",
    "Sq = SchSFind(Q,SimilarityCoeficient)\n",
    "\n",
    "for match in QMGen(Q,Sq|Rq):\n",
    "    pp(match)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação de Candidate Networks\n",
    "\n",
    "Na etapa anterior, obteve-se as full matches, que compreendem todas as informações necessárias para o usuário. O próximo passo é encontrar maneiras de conectar estas informações para formar uma resposta para o usuário. Estas conexões, chamadas de candidate networks, são derivadas das restrições de integridade referencial do banco de dados, também conhecidas como chaves estrangeiras.\n",
    "\n",
    "A criação de candidate networks utiliza dois grafos:\n",
    "- **Schema Graph**: vértice que representa o banco de dados e é utilizado como base para o match graph. Ele contém como vértices os free tuple-sets associados a cada relação do banco de dados e como arestas as restrições de integridade referencial.\n",
    "\n",
    "    O Schema Graph foi implementado como um dicionário, no qual cada vértice aponta para um outro vértice. Além disso, também é armazenada informações sobre as arestas, como direção e quais atributos entre as tabelas tem a relação de restrição referencial. A estrutura do Schema Graph pode ser observada a seguir:\n",
    "   \n",
    "```python\n",
    "    G['table'] = { 'foreign_table' : (direction, column, foreign_column) }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCHEMA CREATED\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'casting': {'char': (1, 'person_role_id', 'id'),\n",
       "  'movie': (1, 'movie_id', 'id'),\n",
       "  'person': (1, 'person_id', 'id'),\n",
       "  'role': (1, 'role_id', 'id')},\n",
       " 'char': {'casting': (-1, 'id', 'person_role_id')},\n",
       " 'movie': {'casting': (-1, 'id', 'movie_id')},\n",
       " 'person': {'casting': (-1, 'id', 'person_id')},\n",
       " 'role': {'casting': (-1, 'id', 'role_id')}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getSchemaGraph():\n",
    "    #Output: A Schema Graph G  with the structure below:\n",
    "    # G['node'] = edges\n",
    "    # G['table'] = { 'foreign_table' : (direction, column, foreign_column) }\n",
    "    \n",
    "    \n",
    "    G = {} \n",
    "    cur.execute(\"SELECT tablename FROM pg_tables WHERE schemaname!='pg_catalog' AND schemaname !='information_schema';\")\n",
    "    for table in cur.fetchall():\n",
    "        G.setdefault(table[0],{})\n",
    "    \n",
    "    sql = \"SELECT DISTINCT                 tc.table_name, kcu.column_name,                 ccu.table_name AS foreign_table_name, ccu.column_name AS foreign_column_name             FROM information_schema.table_constraints AS tc              JOIN information_schema.key_column_usage AS kcu                 ON tc.constraint_name = kcu.constraint_name             JOIN information_schema.constraint_column_usage AS ccu                 ON ccu.constraint_name = tc.constraint_name             WHERE constraint_type = 'FOREIGN KEY'\"\n",
    "    cur.execute(sql)\n",
    "    relations = cur.fetchall()\n",
    "    \n",
    "    for (table,column,foreign_table,foreign_column) in relations:\n",
    "        G[table][foreign_table] = (1,column, foreign_column)\n",
    "        G[foreign_table][table] = (-1,foreign_column,column)\n",
    "    print ('SCHEMA CREATED')\n",
    "    return G\n",
    "getSchemaGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Match Graph**: grafo gerado a partir de uma query match e o schema graph. No entanto, no match graph tuple-sets/schema-sets também são modelados como vértices. Para criá-lo, adiciona-se ao schema graph os tuple-sets/schema-sets presentes na query match. Um tuple-set de uma tabela x terá os mesmos relacionamentos (arestas) que o vértice x.\n",
    "\n",
    "```python\n",
    "    Gts['table'] = { 'foreign_table' : (direction, column, foreign_column) }\n",
    "\n",
    "    Gts[('s','table','column', frozenset({words}))] = { 'foreign_table' : (direction, column, foreign_column) }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MatchGraph(Rq, G, M):\n",
    "    #Input:  The set of non-empty non-free tuple-sets Rq,\n",
    "    #        The Schema Graph G,\n",
    "    #        A Query Match M\n",
    "    #Output: A Schema Graph Gts  with the structure below:\n",
    "    # G['node'] = edges\n",
    "    # G['table'] = { 'foreign_table' : (direction, column, foreign_column) }\n",
    "\n",
    "    '''\n",
    "    A Match Subgraph Gts[M] is a subgraph of G that contains:\n",
    "        The set of free tuple-sets of G\n",
    "        The query match M\n",
    "    '''\n",
    "    \n",
    "    Gts = copy.deepcopy(G)\n",
    "    \n",
    "    tables = set()\n",
    "    #Insert non-free nodes\n",
    "    for (category,table ,attribute, keywords) in M:\n",
    "        Gts[(category,table,attribute,keywords)]=copy.deepcopy(Gts[table])\n",
    "        for foreign_table , (direction,column,foreign_column) in Gts[(category,table,attribute,keywords)].items():\n",
    "            Gts[foreign_table][(category,table,attribute,keywords)] = (direction*(-1),foreign_column,column)\n",
    "\n",
    "    return Gts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'casting': {'char': (1, 'person_role_id', 'id'),\n",
      "             'movie': (1, 'movie_id', 'id'),\n",
      "             'person': (1, 'person_id', 'id'),\n",
      "             'role': (1, 'role_id', 'id'),\n",
      "             ('s', 'person', '*', frozenset({'actor'})): (1, 'person_id', 'id'),\n",
      "             ('v', 'char', 'name', frozenset({'draco'})): (1,\n",
      "                                                           'person_role_id',\n",
      "                                                           'id'),\n",
      "             ('v', 'movie', 'title', frozenset({'potter', 'harry'})): (1,\n",
      "                                                                       'movie_id',\n",
      "                                                                       'id')},\n",
      " 'char': {'casting': (-1, 'id', 'person_role_id')},\n",
      " 'movie': {'casting': (-1, 'id', 'movie_id')},\n",
      " 'person': {'casting': (-1, 'id', 'person_id')},\n",
      " 'role': {'casting': (-1, 'id', 'role_id')},\n",
      " ('s', 'person', '*', frozenset({'actor'})): {'casting': (-1,\n",
      "                                                          'id',\n",
      "                                                          'person_id')},\n",
      " ('v', 'char', 'name', frozenset({'draco'})): {'casting': (-1,\n",
      "                                                           'id',\n",
      "                                                           'person_role_id')},\n",
      " ('v', 'movie', 'title', frozenset({'potter', 'harry'})): {'casting': (-1,\n",
      "                                                                       'id',\n",
      "                                                                       'movie_id')}}\n"
     ]
    }
   ],
   "source": [
    "M = {('s', 'person', '*', frozenset({'actor'})),\n",
    " ('v', 'char', 'name', frozenset({'draco'})),\n",
    " ('v', 'movie', 'title', frozenset({'potter', 'harry'}))}\n",
    "\n",
    "pp(MatchGraph(Rq|Sq, G, M))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo para Criação de Candidate Networks\n",
    "\n",
    "#### \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def containsMatch(Ji,M):\n",
    "    for relation in M:\n",
    "        if relation not in Ji:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def isJNTSound(Gts,Ji):\n",
    "    if len(Ji)<3:\n",
    "        return True\n",
    "    \n",
    "    for i in range(len(Ji)-2):\n",
    "        \n",
    "        if type(Ji[i]) is str:\n",
    "            tableA = Ji[i]\n",
    "        else:\n",
    "            tableA = Ji[i][0]\n",
    "            \n",
    "        if type(Ji[i+2]) is str:\n",
    "            tableB = Ji[i+2]\n",
    "        else:\n",
    "            tableB = Ji[i+2][0]          \n",
    "            \n",
    "        if tableA==tableB:\n",
    "            edge_info = Gts[Ji[i]][Ji[i+1]]\n",
    "            if(edge_info[0] == -1):\n",
    "                return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SingleCN(FM,Gts,Tmax):    \n",
    "    '''\n",
    "    print('================================================================================\\nSINGLE CN')\n",
    "    print('Tmax ',Tmax)\n",
    "    print('FM')\n",
    "    pp(FM)\n",
    "    \n",
    "    print('\\n\\nGts')\n",
    "    pp(Gts)\n",
    "    print('\\n\\n')\n",
    "    '''\n",
    "    F = deque()\n",
    "\n",
    "    first_element = list(FM)[0]\n",
    "    J = [first_element]\n",
    "    \n",
    "    if len(FM)==1:\n",
    "        return J\n",
    "    \n",
    "    F.append(J)\n",
    "    \n",
    "    while F:\n",
    "        J = F.popleft()           \n",
    "        u = J[-1]\n",
    "        '''\n",
    "        print('--------------------------------------------\\nParctial CN')\n",
    "        print('J ',J,'\\n')\n",
    "        \n",
    "        print('\\nAdjacents:')\n",
    "        pp(Gts[u].items())\n",
    "        '''\n",
    "        for (adjacent,edge_info) in Gts[u].items():\n",
    "            if (type(adjacent) is str) or (adjacent not in J):\n",
    "                Ji = J + [adjacent]\n",
    "                if (Ji not in F) and (len(Ji)<Tmax) and (isJNTSound(Gts,Ji)):\n",
    "                    if(containsMatch(Ji,FM)):\n",
    "                        '''\n",
    "                        print('--------------------------------------------\\nGenerated CN')\n",
    "                        print('J ',Ji,'\\n')\n",
    "                        '''\n",
    "                        return Ji\n",
    "                    else:\n",
    "                        F.append(Ji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MatchCN(G,Rq,Mq,SMq):    \n",
    "    \n",
    "    Cns = []                        \n",
    "    for M in Mq: \n",
    "        \n",
    "        FullMatches = FMGen(SMq,M) \n",
    "        \n",
    "        for FM in FullMatches: \n",
    "            \n",
    "            Gts =  MatchGraph(Rq,G,FM)\n",
    "            \n",
    "            Cn = SingleCN(FM,Gts,10)\n",
    "\n",
    "            if(Cn is not None):\n",
    "                Cns.append( (Cn,Gts,FM) )\n",
    "    return Cns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
